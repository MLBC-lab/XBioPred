{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nopFpFQ--u--"
      },
      "outputs": [],
      "source": [
        "# importing packages\n",
        "from itertools import permutations, count\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import set_config\n",
        "from sklearn.model_selection import (train_test_split,\n",
        "                                     cross_val_score,\n",
        "                                     cross_validate,\n",
        "                                     KFold)\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "import optuna\n",
        "from sklearn.metrics import *\n",
        "from sklearn.inspection import *\n",
        "import shap\n",
        "import lovelyplots\n",
        "import statsmodels.api as sm\n",
        "import gc\n",
        "import warnings\n",
        "\n",
        "\n",
        "import scienceplots\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import *\n",
        "from sklearn.metrics import *\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras_tuner\n",
        "\n",
        "\n",
        "import missingno\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plotting Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F_mkLXs0MWWS"
      },
      "outputs": [],
      "source": [
        "plt.rcdefaults()\n",
        "mpl_global_config = {\n",
        "    'figure.figsize': (7, 7),\n",
        "    'figure.dpi': 1000,\n",
        "    'font.size': 16,\n",
        "    'axes.labelsize': 14,\n",
        "    'axes.titlesize': 14,\n",
        "    'xtick.labelsize': 12,\n",
        "    'ytick.labelsize': 12,\n",
        "    'legend.fontsize': 8,\n",
        "    'lines.linewidth': 2,\n",
        "    'lines.markersize': 3,\n",
        "    'grid.linewidth': 0.75,\n",
        "    'savefig.dpi': 1000,\n",
        "    'savefig.transparent': False,\n",
        "    'savefig.bbox': 'tight',\n",
        "    'pdf.compression': 9,\n",
        "    'axes.axisbelow': True\n",
        "}\n",
        "plt.rcParams.update(mpl_global_config)\n",
        "plt.style.use(['science', 'nature', 'high-contrast', \"no-latex\"])\n",
        "\n",
        "\n",
        "colors = {\n",
        "    \"yellow\": \"#DDAA33\",\n",
        "    \"red\": \"#BB5566\",\n",
        "    \"blue\": \"#004488\",\n",
        "    \"black\": \"#000000\",\n",
        "    \"white\": \"#FFFFFF\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global Configuration Setting Controling Randomness, Trials, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KN67q6ey-wgF"
      },
      "outputs": [],
      "source": [
        "# config initialization\n",
        "set_config(transform_output=\"pandas\")\n",
        "np.seterr(under='ignore')\n",
        "warnings.filterwarnings('ignore')\n",
        "SEED = 0\n",
        "n_trials = 75\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# def evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "r5V7R9XiAUM9"
      },
      "outputs": [],
      "source": [
        "def evaluation(trained_model, X, y_real):\n",
        "\n",
        "    y_pred = trained_model.predict(X)\n",
        "\n",
        "    mse = mean_squared_error(y_real, y_pred, squared=True)\n",
        "    rmse = mean_squared_error(y_real, y_pred, squared=False)\n",
        "    mae = mean_absolute_error(y_real, y_pred)\n",
        "    r2 = r2_score(y_real, y_pred)\n",
        "    maxerror = max_error(y_real, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_real, y_pred)\n",
        "\n",
        "    return {\"MeanSquaredError\":mse,\n",
        "            \"RootMeanSquaredError\": rmse,\n",
        "            \"MeanAbsoluteError\": mae,\n",
        "            \"R2\": r2,\n",
        "            \"MaxError\": maxerror,\n",
        "            \"MAPE\": mape}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read the Preprocessed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5RBqBmW-0IN",
        "outputId": "79e5812f-336e-4c75-b2ca-b049cbf6416d"
      },
      "outputs": [],
      "source": [
        "# reading the dataset\n",
        "df = pd.read_csv(\"df.csv\",\n",
        "                 dayfirst=True,\n",
        "                 parse_dates=True,\n",
        "                 index_col=\"Date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "18Mpqkln-6pV"
      },
      "outputs": [],
      "source": [
        "data_summary = df.describe()\n",
        "data_summary.loc[\"Missing Values Ratio\"] = df.isnull().sum().divide(len(df))\n",
        "data_summary.loc[\"Unique Values Ratio\"] = df.nunique().divide(len(df))\n",
        "data_summary.loc[\"Kurtosis\"] = df.kurtosis()\n",
        "data_summary.loc[\"Skewness\"] = df.skew()\n",
        "data_summary.T.to_csv(\"data_summary.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0e9Jdwk94iz"
      },
      "outputs": [],
      "source": [
        "data_summary.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Separating X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ASGkjzew60i",
        "outputId": "efe8fa32-950c-4aa5-e93a-db47c987134c"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=[\"Total Biogas Flowrate (m3/d)\"])\n",
        "y = df.loc[: , \"Total Biogas Flowrate (m3/d)\"]\n",
        "print(f\"dataframe shape: {df.shape}\\n\"\\\n",
        "      f\"features shape: {X.shape}\\n\"\\\n",
        "      f\"target shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train and Test Split and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUrvK4gS_0pF",
        "outputId": "4d2d6691-10df-4f37-a830-4b43607d920c"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.30,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAGURTs489bm",
        "outputId": "64719cbc-20b8-4595-94d9-4d734acf227e"
      },
      "outputs": [],
      "source": [
        "# train a Decision Tree model with tpe sampler and median pruner\n",
        "def objective_dt(trial):\n",
        "\n",
        "    dt_params = {\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 15),\n",
        "            \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.5),\n",
        "        }\n",
        "\n",
        "    model = DecisionTreeRegressor(random_state=SEED, **dt_params)\n",
        "\n",
        "    score = -np.mean(\n",
        "        cross_val_score(\n",
        "                model,\n",
        "                X_train,\n",
        "                y_train,\n",
        "                cv=KFold(n_splits=5),\n",
        "                n_jobs=-1,\n",
        "                scoring='neg_mean_squared_error')\n",
        "        )\n",
        "\n",
        "    return score\n",
        "\n",
        "study_dt = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
        "    pruner=optuna.pruners.HyperbandPruner()\n",
        ")\n",
        "\n",
        "study_dt.optimize(objective_dt, n_trials=n_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEblnp0T9uc4",
        "outputId": "9d1549df-be55-4b16-9db5-c40375c27b56"
      },
      "outputs": [],
      "source": [
        "# train a Random Forest model with tpe sampler and median pruner\n",
        "def objective_rf(trial):\n",
        "\n",
        "    rf_params = {\n",
        "            \"max_features\": trial.suggest_float(\"max_features\", 0.3, 1),\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 15),\n",
        "            \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.5),\n",
        "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [False, True]),\n",
        "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 200)\n",
        "        }\n",
        "\n",
        "    model = RandomForestRegressor(random_state=SEED, **rf_params)\n",
        "\n",
        "\n",
        "    score = -np.mean(\n",
        "        cross_val_score(\n",
        "                model,\n",
        "                X_train,\n",
        "                y_train,\n",
        "                cv=KFold(n_splits=5),\n",
        "                n_jobs=-1,\n",
        "                scoring='neg_mean_squared_error')\n",
        "        )\n",
        "\n",
        "    return score\n",
        "\n",
        "study_rf = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
        "    pruner=optuna.pruners.HyperbandPruner()\n",
        "\n",
        ")\n",
        "\n",
        "study_rf.optimize(objective_rf, n_trials=n_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT_iEdoa-e6h",
        "outputId": "e4387d07-d7d9-43bc-ef37-23bd2825d849"
      },
      "outputs": [],
      "source": [
        "# train an XBGBoost model with tpe sampler and median pruner\n",
        "def objective_xgb(trial):\n",
        "\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 5000),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 1.0, log=True),\n",
        "        \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 0, 20),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\",1e-9, 100.0, log=True),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-9, 100.0, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0, log=True),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0, log=True),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 15),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.1, 0.5, log=True),\n",
        "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1e-6, 500, log=True)\n",
        "    }\n",
        "\n",
        "\n",
        "    model = XGBRegressor(random_state=SEED, objective=\"reg:squarederror\", **params)\n",
        "\n",
        "    score = -np.mean(\n",
        "        cross_val_score(\n",
        "                model,\n",
        "                X_train,\n",
        "                y_train,\n",
        "                cv=KFold(n_splits=5),\n",
        "                n_jobs=-1,\n",
        "                scoring='neg_mean_squared_error')\n",
        "        )\n",
        "\n",
        "    return score\n",
        "\n",
        "study_xgb = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
        "    pruner=optuna.pruners.HyperbandPruner()\n",
        ")\n",
        "\n",
        "study_xgb.optimize(objective_xgb, n_trials=n_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hps = {\n",
        "    \"DecisionTree\": study_dt.best_params,\n",
        "    \"RandomForest\": study_rf.best_params,\n",
        "    \"XGBoost\": study_xgb.best_params,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hps = {'DecisionTree': {'max_depth': 14, 'min_samples_leaf': 0.010039169930176879},\n",
        "            'RandomForest': {'max_features': 0.38554104875151896,\n",
        "            'max_depth': 10,\n",
        "            'min_samples_leaf': 0.010168225931922027,\n",
        "            'bootstrap': False,\n",
        "            'n_estimators': 124},\n",
        "            'XGBoost': {'n_estimators': 4860,\n",
        "            'learning_rate': 0.49003165411341526,\n",
        "            'max_delta_step': 20,\n",
        "            'reg_lambda': 1.1231181925328875e-05,\n",
        "            'reg_alpha': 3.426318577751964e-08,\n",
        "            'subsample': 0.89607666469783,\n",
        "            'colsample_bytree': 0.8147384539995441,\n",
        "            'max_depth': 4,\n",
        "            'min_child_weight': 10,\n",
        "            'gamma': 0.1296891015376799,\n",
        "            'scale_pos_weight': 2.2740058630279575e-05}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fitting the Models with Best HPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2_KMb_YbAbgN"
      },
      "outputs": [],
      "source": [
        "\n",
        "trained_models = {\n",
        "    \"DecisionTree\": DecisionTreeRegressor(random_state=SEED,\n",
        "                                          **best_hps[\"DecisionTree\"]).fit(X_train, y_train),\n",
        "\n",
        "    \"RandomForest\": RandomForestRegressor(random_state=SEED,\n",
        "                                          **best_hps[\"RandomForest\"]).fit(X_train, y_train),\n",
        "\n",
        "\n",
        "    \"XGBoost\": XGBRegressor(random_state=SEED,\n",
        "                            **best_hps[\"XGBoost\"],\n",
        "                            objective=\"reg:squarederror\").fit(X_train, y_train),\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "twQCsMdNMTYL"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame.from_dict(best_hps, orient=\"index\").T.to_csv(\"hyperparameters_when_all_features_are_chosen.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9wlhEZC-AebG"
      },
      "outputs": [],
      "source": [
        "evaluations_dictionary = {\n",
        "    \"DecisionTree_Train\": evaluation(trained_models[\"DecisionTree\"],\n",
        "                                     X_train, y_train),\n",
        "    \"DecisionTree_Test\": evaluation(trained_models[\"DecisionTree\"],\n",
        "                                    X_test, y_test),\n",
        "\n",
        "    \"RandomForest_Train\": evaluation(trained_models[\"RandomForest\"],\n",
        "                                     X_train, y_train),\n",
        "    \"RandomForest_Test\": evaluation(trained_models[\"RandomForest\"],\n",
        "                                    X_test, y_test),\n",
        "\n",
        "    \"XGBoost_Train\": evaluation(trained_models[\"XGBoost\"],\n",
        "                                X_train, y_train),\n",
        "    \"XGBoost_Test\": evaluation(trained_models[\"XGBoost\"],\n",
        "                               X_test, y_test),\n",
        "\n",
        "}\n",
        "\n",
        "evaluation_df = pd.DataFrame(evaluations_dictionary)\n",
        "evaluation_df.T.to_csv(\"model_evaluation.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "AeZcV_vHfEn0",
        "outputId": "2cc0f932-f745-4b98-84a3-66c311a72247"
      },
      "outputs": [],
      "source": [
        "evaluation_df.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the R² values for each model\n",
        "models = ['ANN', 'Decision Tree', 'Random Forest', 'XGBoost']\n",
        "\n",
        "# R² values for training and testing data\n",
        "train_r2 = [0.81, 0.92, 0.95, 1.00]  # R² for Train\n",
        "test_r2 = [0.80, 0.76, 0.86, 0.97]   # R² for Test\n",
        "\n",
        "# Function to create radar plot\n",
        "def create_combined_radar_plot(train_data, test_data):\n",
        "    num_vars = len(models)\n",
        "\n",
        "    # Compute angle for each axis\n",
        "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "\n",
        "    # Complete the loop by appending the first value to the end\n",
        "    train_data = np.concatenate((train_data, [train_data[0]]))\n",
        "    test_data = np.concatenate((test_data, [test_data[0]]))\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Create the radar chart\n",
        "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
        "    \n",
        "    # Plot training data\n",
        "    ax.fill(angles, train_data, color='blue', alpha=0.25, label='Training R²')\n",
        "    ax.plot(angles, train_data, color='blue', linewidth=2)\n",
        "    \n",
        "    # Plot testing data\n",
        "    ax.fill(angles, test_data, color='orange', alpha=0.25, label='Testing R²')\n",
        "    ax.plot(angles, test_data, color='orange', linewidth=2)\n",
        "\n",
        "    # Add labels to each axis\n",
        "    plt.xticks(angles[:-1], models)\n",
        "    \n",
        "    # Add title and legend\n",
        "    plt.title('R² Values for Training and Testing Metrics')\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "# Create combined radar plot for R² values\n",
        "create_combined_radar_plot(train_r2, test_r2)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a DataFrame with the provided data\n",
        "data = {\n",
        "    'Model': ['ANN', 'ANN', 'DT', 'DT', 'RF', 'RF', 'XGBoost', 'XGBoost'],\n",
        "    'Phase': ['Train', 'Test', 'Train', 'Test', 'Train', 'Test', 'Train', 'Test'],\n",
        "    'RMSE': [4297, 4332, 2684, 4914, 2089, 3779, 9, 1809],\n",
        "    'MAE': [2664, 2562, 1305, 2412, 1070, 1969, 5, 1148],\n",
        "    'R2': [0.81, 0.80, 0.92, 0.76, 0.95, 0.86, 1.00, 0.97],\n",
        "    'MAPE': [0.09, 0.08, 0.04, 0.08, 0.04, 0.06, 0.00, 0.04]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.35\n",
        "\n",
        "# Set positions of bar on X axis\n",
        "r1 = np.arange(len(df[df['Phase'] == 'Train']))\n",
        "r2 = [x + bar_width for x in r1]\n",
        "\n",
        "# Create subplots for each metric\n",
        "metrics = ['RMSE', 'MAE', 'R2', 'MAPE']\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# Loop through each metric and create a bar plot\n",
        "for i, metric in enumerate(metrics):\n",
        "    # Plotting training data\n",
        "    train_bars = axs[i].bar(r1, df[df['Phase'] == 'Train'][metric], color='blue', width=bar_width / 2,\n",
        "                            label='Train')\n",
        "    \n",
        "    # Plotting testing data\n",
        "    test_bars = axs[i].bar(r2, df[df['Phase'] == 'Test'][metric], color='orange', width=bar_width / 2,\n",
        "                           label='Test')\n",
        "\n",
        "    # Adding labels and title\n",
        "    axs[i].set_xlabel('Models')\n",
        "    axs[i].set_ylabel(metric)\n",
        "    axs[i].set_title(f'{metric} Comparison')\n",
        "    axs[i].set_xticks([r + bar_width / 4 for r in r1])\n",
        "    axs[i].set_xticklabels(df['Model'].unique())\n",
        "    axs[i].legend()\n",
        "\n",
        "    # Adding values on top of bars\n",
        "    for bar in train_bars:\n",
        "        yval = bar.get_height()\n",
        "        axs[i].text(bar.get_x() + bar.get_width()/2 - bar_width/4, yval + (yval * 0.02), \n",
        "                     f'{yval:.2f}', ha='center', va='bottom')\n",
        "\n",
        "    for bar in test_bars:\n",
        "        yval = bar.get_height()\n",
        "        axs[i].text(bar.get_x() + bar.get_width()/2 + bar_width/4, yval + (yval * 0.02), \n",
        "                     f'{yval:.2f}', ha='center', va='bottom')\n",
        "    plt.savefig(f\"evaluation metrics comparision.svg\")\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the R² values for each model\n",
        "models = ['ANN', 'Decision Tree', 'Random Forest', 'XGBoost']\n",
        "\n",
        "# R² values for training and testing data\n",
        "train_r2 = [0.81, 0.92, 0.95, 1.00]  # R² for Train\n",
        "test_r2 = [0.80, 0.76, 0.86, 0.97]   # R² for Test\n",
        "\n",
        "# Function to create an improved radar plot\n",
        "def create_improved_radar_plot(train_data, test_data):\n",
        "    num_vars = len(models)\n",
        "\n",
        "    # Compute angle for each axis\n",
        "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "\n",
        "    # Complete the loop by appending the first value to the end\n",
        "    train_data = np.concatenate((train_data, [train_data[0]]))\n",
        "    test_data = np.concatenate((test_data, [test_data[0]]))\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Create the radar chart with higher resolution\n",
        "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True), dpi=150)\n",
        "    \n",
        "    # Plot training data with bold lines and black color\n",
        "    ax.fill(angles, train_data, color='blue', alpha=0.25, label='Training R²')\n",
        "    ax.plot(angles, train_data, color='blue', linewidth=3)  # Bold line\n",
        "    \n",
        "    # Plot testing data with bold lines and a different color\n",
        "    ax.fill(angles, test_data, color='red', alpha=0.25, label='Testing R²')\n",
        "    ax.plot(angles, test_data, color='red', linewidth=3)  # Bold line\n",
        "\n",
        "    # Add labels to each axis in bold font\n",
        "    plt.xticks(angles[:-1], models, fontweight='bold')\n",
        "    \n",
        "    # Add title and legend with bold font\n",
        "    plt.title('R² Values for Training and Testing Metrics', fontweight='bold')\n",
        "    plt.legend(loc='upper right', frameon=True)\n",
        "\n",
        "# Create improved radar plot for R² values\n",
        "create_improved_radar_plot(train_r2, test_r2)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use(['science', 'nature', 'high-contrast', \"no-latex\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model in trained_models.keys():\n",
        "    for dataset in [(\"Train\", X_train, y_train), (\"Test\", X_test, y_test)]:\n",
        "        data_type, X_data, y_data = dataset\n",
        "        fig, ax = plt.subplots(figsize=(7, 7))\n",
        "        PredictionErrorDisplay.from_estimator(\n",
        "            trained_models[model],\n",
        "            X_data,\n",
        "            y_data,\n",
        "            kind=\"actual_vs_predicted\",\n",
        "            scatter_kwargs={\"alpha\": 1,\n",
        "                            \"color\": \"#004488\",  \n",
        "                            \"label\": f\"{data_type} MAE: {int(evaluation_df.loc['MeanAbsoluteError', f'{model}_{data_type}'].round(0))}\", \n",
        "                            \"s\":45},\n",
        "            line_kwargs={\"color\": \"black\"},\n",
        "            ax=ax)\n",
        "\n",
        "        ax.set_ylabel(f\"Actual {y.name}\", fontsize=14, fontweight='bold')  \n",
        "        ax.set_xlabel(f\"Predicted {y.name}\", fontsize=14, fontweight='bold')  \n",
        "        ax.legend(fontsize=9, loc=\"upper left\", fancybox=True, shadow=True, ncol=1, frameon=False)  \n",
        "        ax.tick_params(axis='x', labelsize=12)  # Increased font size for x-axis numbers\n",
        "        ax.tick_params(axis='y', labelsize=12)  # Increased font size for y-axis numbers\n",
        "        \n",
        "        from matplotlib.ticker import AutoMinorLocator  # Import minor locator\n",
        "        ax.xaxis.set_minor_locator(AutoMinorLocator(2))  # Add minor ticks to x-axis\n",
        "        ax.yaxis.set_minor_locator(AutoMinorLocator(2))  # Add minor ticks to y-axis\n",
        "        \n",
        "        ax.grid(False)  # Disable gridlines\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"evaluation actual_vs_predicted_{model}_{data_type}.svg\")\n",
        "        # plt.close()\n",
        "        # gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki-q5uf1jl3o"
      },
      "outputs": [],
      "source": [
        "for model in trained_models.keys():\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    PredictionErrorDisplay.from_estimator(\n",
        "        trained_models[model],\n",
        "        X_test,\n",
        "        y_test,\n",
        "        kind=\"residual_vs_predicted\",\n",
        "        scatter_kwargs={\"alpha\": 1,\n",
        "                        \"s\":40,\n",
        "                        \"color\": \"#DD3C2D\",\n",
        "                        \"label\": f\"Test R2: {evaluation_df.loc['R2', f'{model}_Test'].round(3)}\",\n",
        "                        },\n",
        "        line_kwargs={\"color\": \"black\"},\n",
        "        ax=ax)\n",
        "\n",
        "\n",
        "    PredictionErrorDisplay.from_estimator(\n",
        "        trained_models[model],\n",
        "        X_train,\n",
        "        y_train,\n",
        "        kind=\"residual_vs_predicted\",\n",
        "        scatter_kwargs={\"alpha\": 0.3,\n",
        "                        \"s\":40,\n",
        "                        \"color\": \"#364B9A\",\n",
        "                        \"label\": f\"Train R2: {evaluation_df.loc['R2', f'{model}_Train'].round(3)}\",\n",
        "                        \"marker\": \"X\"\n",
        "                        },\n",
        "        line_kwargs={\"color\": \"black\"},\n",
        "        ax=ax)\n",
        "\n",
        "\n",
        "\n",
        "    ax.set_xlabel(f\"Predicted {y.name}\", fontsize=14)\n",
        "    ax.set_ylabel(f\"Residuals\\n(Actual - Predicted)\", fontsize=14)\n",
        "    ax.legend(fontsize=9, loc=\"lower left\", fancybox=True, shadow=True, ncol=1)\n",
        "    ax.tick_params(axis='x', labelsize=9)\n",
        "    ax.tick_params(axis='y', labelsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"evaluation_residual_{model}.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "    # plt.close()\n",
        "    # gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWj90ljMnhs-"
      },
      "outputs": [],
      "source": [
        "for model in trained_models.keys():\n",
        "    residuals = y_test - trained_models[model].predict(X_test)\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    sm.qqplot(residuals, line ='q', ax=ax)\n",
        "    ax.set_ylabel(\"Sample Quantiles\", fontsize=14)\n",
        "    ax.set_xlabel(\"Theoretical Quantiles\", fontsize=14)\n",
        "    ax.tick_params(axis='x', labelsize=9)\n",
        "    ax.tick_params(axis='y', labelsize=9)\n",
        "    plt.savefig(f\"evaluation qqplot_{model}.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "    # plt.close()\n",
        "    # gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asFeW8Xbqpet"
      },
      "outputs": [],
      "source": [
        "for model in trained_models.keys():\n",
        "    residuals_test = y_test - trained_models[model].predict(X_test)\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    ax.text(0.63, 0.7,\n",
        "            f\"Mean: {residuals_test.mean().round(3)}\\nStd: {residuals_test.std().round(3)}\",\n",
        "            transform=ax.transAxes, fontsize=9)\n",
        "    sns.kdeplot(residuals_test, ax=ax, label=f\"{model}\", color=\"#6EA5CD\", linewidth=2)\n",
        "    ax.set_ylabel(\"Density\", fontsize=14)\n",
        "    ax.set_xlabel(\"Error\", fontsize=14)\n",
        "    plt.legend(fontsize=9, loc=\"upper left\", fancybox=True, shadow=True, ncols=1)\n",
        "    ax.tick_params(axis='x', labelsize=9)\n",
        "    ax.tick_params(axis='y', labelsize=9)\n",
        "    plt.savefig(f\"Evaluation_kde_residuals_{model}.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "#     plt.close()\n",
        "#     gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjmqixFedGGK"
      },
      "source": [
        "## Explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cCOYcexadFrl"
      },
      "outputs": [],
      "source": [
        "plt.rcdefaults()\n",
        "# plt.style.use()\n",
        "\n",
        "\n",
        "mpl_global_config = {\n",
        "    'figure.dpi': 100,\n",
        "    'savefig.dpi': 1200,\n",
        "    'savefig.transparent': False,\n",
        "    'savefig.bbox': 'tight',\n",
        "    'axes.axisbelow': True,\n",
        "    'axes.spines.top': True,\n",
        "    'axes.spines.right': True,\n",
        "    'axes.spines.bottom': True,\n",
        "    'axes.spines.left': True,\n",
        "    \"axes.grid\": True,\n",
        "    'grid.linewidth': 0.3,\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "plt.rcParams.update(mpl_global_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3ES1qKrU169U"
      },
      "outputs": [],
      "source": [
        "explainer = shap.TreeExplainer(trained_models[\"XGBoost\"])\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap_interaction_values = explainer.shap_interaction_values(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7Jdyx9PYL3C",
        "outputId": "8b0645a5-e3ea-443b-943b-31633df6780d"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", color=\"#DD3C2D\", show=False, max_display=30)\n",
        "plt.gca().spines['top'].set_visible(True)\n",
        "plt.gca().spines['right'].set_visible(True)\n",
        "plt.gca().spines['bottom'].set_visible(True)\n",
        "plt.gca().spines['left'].set_visible(True)\n",
        "plt.gca().spines['top'].set_color('black')\n",
        "plt.gca().spines['right'].set_color('black')\n",
        "plt.gca().spines['bottom'].set_color('black')\n",
        "plt.gca().spines['left'].set_color('black')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"Explanation_FeatureImportancePlot.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
        "# plt.close()\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "# Generate the SHAP summary plot\n",
        "shap.summary_plot(shap_values, X_test, show=False, max_display=30)\n",
        "\n",
        "# Customize spines (axis lines)\n",
        "ax = plt.gca()  # Get current axes\n",
        "ax.spines['top'].set_visible(True)\n",
        "ax.spines['right'].set_visible(True)\n",
        "ax.spines['bottom'].set_visible(True)\n",
        "ax.spines['left'].set_visible(True)\n",
        "\n",
        "# Set spine colors and widths\n",
        "for spine in ax.spines.values():\n",
        "    spine.set_color('black')  # Set spine color to black\n",
        "    spine.set_linewidth(2)     # Make spines bolder\n",
        "\n",
        "# Set title and labels in bold black\n",
        "plt.title('SHAP Summary Plot', color='black', fontsize=14, fontweight='bold')  # Title in bold black\n",
        "\n",
        "# Customize tick parameters to bold the numbers\n",
        "ax.tick_params(axis='both', which='major', labelcolor='black', labelsize=12)  # Increased font size for major ticks\n",
        "for tick in ax.get_xticklabels() + ax.get_yticklabels():  # Get all tick labels\n",
        "    tick.set_fontsize(12)  # Increased font size for tick labels\n",
        "    tick.set_fontweight('bold')  # Set font weight to bold\n",
        "\n",
        "# Increase space between x label and axis\n",
        "ax.set_xlabel('SHAP Value (impact on model output)', labelpad=15, color='black', fontsize=12, fontweight='bold')  # Adjust labelpad as needed\n",
        "\n",
        "# Save the plot with a specified filename\n",
        "plt.savefig(\"Explanation_SummaryImportancePlot_2.svg\", format='svg', dpi=3000, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "for main_feature in list(X_test.columns):\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))  # Set figure size\n",
        "    \n",
        "    # Generate the SHAP dependence plot\n",
        "    shap.dependence_plot(\n",
        "        (main_feature, main_feature),\n",
        "        shap_interaction_values, X_test,\n",
        "        display_features=X_test.iloc[:, :],\n",
        "        dot_size=50,  # Increase dot size for better visibility\n",
        "        show=False,\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    # Customize spines (axis lines)\n",
        "    ax.spines['top'].set_visible(True)\n",
        "    ax.spines['right'].set_visible(True)\n",
        "    ax.spines['bottom'].set_visible(True)\n",
        "    ax.spines['left'].set_visible(True)\n",
        "    \n",
        "    # Set spine colors and widths\n",
        "    for spine in ax.spines.values():\n",
        "        spine.set_color('black')  # Set spine color to black\n",
        "        spine.set_linewidth(2)     # Make spines bolder\n",
        "\n",
        "    # Set title and labels in bold black\n",
        "    plt.title(f'SHAP Dependence Plot for {main_feature}', color='black', fontsize=14, fontweight='bold')  # Title in bold black\n",
        "    plt.xlabel(main_feature, color='black', fontsize=12, fontweight='bold')  # X-axis label in bold black\n",
        "    plt.ylabel('SHAP Value', color='black', fontsize=12, fontweight='bold')  # Y-axis label in bold black\n",
        "\n",
        "    # Customize tick parameters to bold the numbers\n",
        "    ax.tick_params(axis='both', which='major', labelcolor='black', labelsize=10)  # Major ticks in black\n",
        "    for tick in ax.get_xticklabels() + ax.get_yticklabels():  # Get all tick labels\n",
        "        tick.set_fontsize(10)  # Set font size for tick labels\n",
        "        tick.set_fontweight('bold')  # Set font weight to bold\n",
        "\n",
        "    # Manually plot the markers in blue\n",
        "    scatter = ax.collections[0]  # Get the scatter collection from the dependence plot\n",
        "    scatter.set_facecolor('blue')  # Change marker color to blue\n",
        "\n",
        "    # Save the plot with a modified filename to avoid issues with slashes\n",
        "    main_feature_safe = main_feature.replace(\"/\", \"\")  # Remove slashes from feature names\n",
        "    plt.savefig(f\"Explanation_Singular_{main_feature_safe}_dependence_plot.svg\", format='svg', dpi=3000, bbox_inches='tight')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute SHAP values\n",
        "shap_values = explainer(X_test[:1000])\n",
        "\n",
        "shap.plots.heatmap(shap_values, instance_order=shap_values.sum(1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.scatter(shap_values[:, \"Temperature (Degrees Celsius)\"], color=shap_values[:, \"Alkalinity (mg CaCO3/L)\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "clustering = shap.utils.hclust(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.bar(shap_values, clustering=clustering, clustering_cutoff=0.8, show=False)\n",
        "\n",
        "# Customize the ticks and labels for the existing plot\n",
        "plt.xticks(fontsize=18, fontweight=\"bold\", color=\"black\")  # Bold and black x-ticks\n",
        "plt.yticks(fontsize=18, fontweight=\"bold\", color=\"black\")  # Bold and black y-ticks\n",
        "\n",
        "# Customize the axis labels\n",
        "plt.xlabel(plt.gca().get_xlabel(), fontsize=14, fontweight=\"bold\", color=\"black\")  # Bold and black x-axis label\n",
        "plt.ylabel(plt.gca().get_ylabel(), fontsize=14, fontweight=\"bold\", color=\"black\")  # Bold and black y-axis label\n",
        "\n",
        "\n",
        "plt.savefig(\"bar_plot.svg\", format='svg', dpi=3000, bbox_inches='tight')\n",
        "\n",
        "# Display the updated plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.bar(shap_values, clustering=clustering, clustering_cutoff=0.7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.beeswarm(shap_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "# Create the SHAP scatter plot\n",
        "scatter_plot = shap.plots.scatter(shap_values[:, \"Temperature (Degrees Celsius)\"], show=False)\n",
        "\n",
        "# Customize the ticks and labels for the existing plot\n",
        "plt.xticks(fontsize=12, fontweight=\"bold\", color=\"black\")  # Bold and black x-ticks\n",
        "plt.yticks(fontsize=12, fontweight=\"bold\", color=\"black\")  # Bold and black y-ticks\n",
        "\n",
        "# Customize the axis labels\n",
        "plt.xlabel(plt.gca().get_xlabel(), fontsize=14, fontweight=\"bold\", color=\"black\")  # Bold and black x-axis label\n",
        "plt.ylabel(plt.gca().get_ylabel(), fontsize=14, fontweight=\"bold\", color=\"black\")  # Bold and black y-axis label\n",
        "\n",
        "# Display the updated plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "# Generate SHAP scatter plots for each feature in X_test\n",
        "for main_feature in X_test.columns:\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))  # Set figure size\n",
        "    \n",
        "    # Generate the SHAP scatter plot for the current feature\n",
        "    shap.plots.scatter(shap_values[:, main_feature], show=False, ax=ax)\n",
        "\n",
        "    # Customize spines (axis lines)\n",
        "    ax.spines['top'].set_visible(True)\n",
        "    ax.spines['right'].set_visible(True)\n",
        "    ax.spines['bottom'].set_visible(True)\n",
        "    ax.spines['left'].set_visible(True)\n",
        "\n",
        "    # Set spine colors and widths\n",
        "    for spine in ax.spines.values():\n",
        "        spine.set_color('black')  # Set spine color to black\n",
        "        spine.set_linewidth(2)     # Make spines bolder\n",
        "\n",
        "    # Set title and labels in bold black\n",
        "    plt.title(f'SHAP Scatter Plot for {main_feature}', color='black', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel(main_feature, color='black', fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('SHAP Value', color='black', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Customize tick parameters to bold the numbers\n",
        "    ax.tick_params(axis='both', which='major', labelcolor='black', labelsize=10)\n",
        "    for tick in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "        tick.set_fontsize(10)\n",
        "        tick.set_fontweight('bold')\n",
        "\n",
        "    # Manually plot the markers in blue\n",
        "    scatter = ax.collections[0]  # Get the scatter collection from the scatter plot\n",
        "    scatter.set_facecolor('blue')  # Change marker color to blue\n",
        "\n",
        "    # Save the plot with a modified filename to avoid issues with slashes\n",
        "    main_feature_safe = main_feature.replace(\"/\", \"\")  # Remove slashes from feature names\n",
        "    plt.savefig(f\"Explanation_Singular_{main_feature_safe}_scatter_plot.svg\", format='svg', dpi=3000, bbox_inches='tight')\n",
        "\n",
        "# Optionally show the last plot (if needed)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Create a SHAP force plot\n",
        "shap.force_plot(\n",
        "    explainer.expected_value, \n",
        "    shap_values.values, \n",
        "    X_test, \n",
        "    feature_names=['Temperature (Degrees Celsius)', 'DS of Influent Primary Sludge (%)',\n",
        "                   'Influent Primary to Waste Sludge flowrate Ratio',\"Alkalinity (mg CaCO3/L)\"],\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sum of absolute SHAP values for each instance\n",
        "impact_scores = np.sum(np.abs(shap_values.values), axis=1)\n",
        "\n",
        "# Find the instance with the highest impact\n",
        "highest_impact_index = np.argmax(impact_scores)\n",
        "highest_impact_instance = shap_values[highest_impact_index]\n",
        "\n",
        "print(f\"Highest impact instance index: {highest_impact_index}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize JavaScript visualization for SHAP\n",
        "shap.initjs()\n",
        "\n",
        "# Force plot for one instance\n",
        "shap.force_plot(\n",
        "    explainer.expected_value,  # Model's base value\n",
        "    shap_values[highest_impact_index].values,     # SHAP values for the instance\n",
        "    X_test.iloc[highest_impact_index]             # Feature values for the instance\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select the best instance (index or specific row)\n",
        "instance = X_test.iloc[highest_impact_index]\n",
        "\n",
        "# Generate the waterfall plot\n",
        "shap.waterfall_plot(\n",
        "    shap.Explanation(values=shap_values[highest_impact_index].values,\n",
        "                     base_values=shap_values[highest_impact_index].base_values,\n",
        "                     data=instance)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sum of absolute SHAP values for each instance\n",
        "impact_scores = np.sum(np.abs(shap_values.values), axis=1)\n",
        "\n",
        "# Find the instance with the highest impact\n",
        "lowest_impact_index = np.argmin(impact_scores)\n",
        "lowest_impact_instance = shap_values[highest_impact_index]\n",
        "\n",
        "print(f\"Lowest impact instance index: {lowest_impact_index}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize JavaScript visualization for SHAP\n",
        "shap.initjs()\n",
        "\n",
        "# Force plot for one instance\n",
        "shap.force_plot(\n",
        "    explainer.expected_value,  # Model's base value\n",
        "    shap_values[lowest_impact_index].values,     # SHAP values for the instance\n",
        "    X_test.iloc[lowest_impact_index]             # Feature values for the instance\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select the best instance (index or specific row)\n",
        "instance = X_test.iloc[lowest_impact_index]\n",
        "\n",
        "# Generate the waterfall plot\n",
        "shap.waterfall_plot(\n",
        "    shap.Explanation(values=shap_values[lowest_impact_index].values,\n",
        "                     base_values=shap_values[lowest_impact_index].base_values,\n",
        "                     data=instance)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the variability of SHAP values (e.g., standard deviation) for each instance\n",
        "shap_variability = np.std(shap_values.values, axis=1)\n",
        "\n",
        "# Find the instance with the highest variability\n",
        "best_instance_index = np.argmax(shap_variability)\n",
        "best_instance = X_test.iloc[best_instance_index]\n",
        "\n",
        "\n",
        "# Select the best instance (index or specific row)\n",
        "instance = X_test.iloc[best_instance_index]\n",
        "\n",
        "# Generate the waterfall plot\n",
        "shap.waterfall_plot(\n",
        "    shap.Explanation(values=shap_values[best_instance_index].values,\n",
        "                     base_values=shap_values[best_instance_index].base_values,\n",
        "                     data=instance)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decision plot for multiple instances\n",
        "shap.decision_plot(explainer.expected_value, shap_values.values[:100], X_test.iloc[:100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Generate SHAP scatter plots for each feature in X_test\n",
        "for main_feature in X_test.columns:\n",
        "    for color_feature in X_test.columns:\n",
        "        if main_feature != color_feature:  # Avoid coloring by the same feature\n",
        "            fig, ax = plt.subplots(figsize=(7, 7))  # Set figure size\n",
        "            \n",
        "            # Generate the SHAP scatter plot for the current feature\n",
        "            shap.plots.scatter(\n",
        "                shap_values[:, main_feature],  # SHAP values for the current feature\n",
        "                color=shap_values[:, color_feature],  # Color based on another feature's SHAP values\n",
        "                show=False, \n",
        "                ax=ax\n",
        "            )\n",
        "\n",
        "            # Customize spines (axis lines)\n",
        "            for spine in ax.spines.values():\n",
        "                spine.set_visible(True)\n",
        "                spine.set_color('black')  # Set spine color to black\n",
        "                spine.set_linewidth(2)     # Make spines bolder\n",
        "\n",
        "            # Set title and labels in bold black\n",
        "            plt.title(f'SHAP Scatter Plot for {main_feature} colored by {color_feature}', \n",
        "                      color='black', fontsize=14, fontweight='bold')\n",
        "            plt.xlabel(main_feature, color='black', fontsize=12, fontweight='bold')\n",
        "            plt.ylabel('SHAP Value', color='black', fontsize=12, fontweight='bold')\n",
        "\n",
        "            # Customize tick parameters to bold the numbers\n",
        "            ax.tick_params(axis='both', which='major', labelcolor='black', labelsize=10)\n",
        "            for tick in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "                tick.set_fontsize(10)\n",
        "                tick.set_fontweight('bold')\n",
        "\n",
        "            # Manually plot the markers in blue\n",
        "            scatter = ax.collections[0]  # Get the scatter collection from the scatter plot\n",
        "            scatter.set_facecolor('blue')  # Change marker color to blue\n",
        "\n",
        "            # Save the plot with a modified filename to avoid issues with slashes\n",
        "            main_feature_safe = main_feature.replace(\"/\", \"\")  # Remove slashes from feature names\n",
        "            color_feature_safe = color_feature.replace(\"/\", \"\")  # Remove slashes from feature names\n",
        "            plt.savefig(f\"Explanation_Singular_{main_feature_safe}_colored_by_{color_feature_safe}_scatter_plot.svg\", \n",
        "                        format='svg', dpi=3000, bbox_inches='tight')\n",
        "\n",
        "# Optionally show the last plot (if needed)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "518jqDlKxIQT"
      },
      "outputs": [],
      "source": [
        "# download results\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile(\"TreeBasedModels.zip\", \"w\") as z:\n",
        "    for file in os.listdir():\n",
        "        if file.endswith((\".svg\", \".csv\")):\n",
        "            z.write(file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
